"""Trigger patterns and importance scoring.

Ported from Mahmory v6 ``memory_skill.py`` / ``importance.py``, cleaned up
and adapted for Turkish+English environment.
"""

from __future__ import annotations

import os
import re
from typing import Dict, List, Optional

# ---------------------------------------------------------------------------
# Trigger patterns
# ---------------------------------------------------------------------------

TURKISH_TRIGGERS: List[str] = [
    # Memory / recall
    r"hatÄ±rl", r"hatirl",
    r"neydi",
    r"ne\s*konuÅŸtuk", r"ne\s*konustuk",
    # Time references
    r"dÃ¼n", r"dun",
    r"geÃ§en", r"gecen",
    r"Ã¶nceki", r"onceki",
    r"ne\s*zaman",
    # Past discussion
    r"bahsetmiÅŸtik", r"bahsetmistik",
    r"sÃ¶ylemiÅŸtik", r"soylemistik",
    r"sÃ¶ylemiÅŸtim", r"soylemistim",
    # Decision / preference
    r"karar",
    r"sevdiÄŸim", r"sevdigim", r"sevmediÄŸim", r"sevmedigim",
    r"unutma",
    r"her\s*zaman", r"asla",
    # Identity
    r"benim\s*(?:adÄ±m|ismim)",
    r"benim\s*(?:adim|ismim)",
    # Context questions
    r"ne\s*yapÄ±yorduk", r"ne\s*yapiyorduk",
    r"neredeydi",
    r"nerede\s*kaldÄ±k", r"nerede\s*kaldik",
    r"devam",
    r"son\s*durum",
    r"hakkÄ±nda", r"hakkinda",
    r"ile\s*ilgili",
    r"konusunda",
]

ENGLISH_TRIGGERS: List[str] = [
    r"remember", r"recall",
    r"what\s*did\s*(?:we|[iI])\s*(?:say|talk|discuss)",
    r"last\s*time", r"previously",
    r"my\s*(?:favorite|favourite|name|preference)",
    r"[iI]\s*(?:like|prefer|hate|love|want|need)",
    r"always", r"never", r"important",
    r"where\s*were\s*we",
    r"what\s*were\s*we",
    r"continue", r"resume",
    r"left\s*off", r"working\s*on",
    r"about", r"regarding",
]

# Patterns for messages that should NOT trigger memory search
ANTI_TRIGGER_PATTERNS: List[str] = [
    r"^(?:ok|tamam|evet|hayÄ±r|hayir|anladÄ±m|anladim|ðŸ‘|ðŸ˜‚|ðŸ˜Š|ðŸ™)$",
    r"^(?:merhaba|selam|hey|hi|hello|nasÄ±lsÄ±n|nasilsin|naber)[\s?!]*$",
    r"^(?:teÅŸekkÃ¼r|tesekkur|saÄŸol|sagol|thanks|thx)[\s!]*$",
    r"^(?:yap|oluÅŸtur|olustur|gÃ¶nder|gonder|aÃ§|ac|kapat|baÅŸla|basla|bitir)[\s!]*$",
]

# Past-tense heuristic (Turkish + English)
_PAST_TENSE_RE = re.compile(
    r"(?:mÄ±ÅŸtÄ±|misti|miÅŸti|muÅŸtu|mustu|mÃ¼ÅŸtÃ¼|dÄ±k|dik|duk|dÃ¼k|aldÄ±|aldi|yaptÄ±|yapti|gitti|geldi|sÃ¶yledi|soyledi"
    r"|was|were|did|had)",
    re.IGNORECASE,
)


def should_trigger(text: str) -> bool:
    """Determine whether *text* should trigger a memory search.

    Returns ``True`` if any trigger pattern matches and no anti-trigger fires.
    """
    text_stripped = text.strip()
    text_lower = text_stripped.lower()

    # Anti-triggers
    for pattern in ANTI_TRIGGER_PATTERNS:
        if re.match(pattern, text_stripped, re.IGNORECASE | re.UNICODE):
            return False

    # Too short
    if len(text_stripped) < 3:
        return False

    # Too generic (single common words)
    if text_lower in {"o", "ÅŸey", "sey", "bu", "ÅŸu", "su", "ne", "it", "that", "this"}:
        return False

    # Single emoji
    if len(text_stripped) <= 4 and not any(c.isalpha() for c in text_stripped):
        return False

    # Check Turkish triggers
    for pattern in TURKISH_TRIGGERS:
        if re.search(pattern, text_lower, re.IGNORECASE):
            return True

    # Check English triggers
    for pattern in ENGLISH_TRIGGERS:
        if re.search(pattern, text_lower, re.IGNORECASE):
            return True

    # Question mark heuristic (long enough question)
    if "?" in text and len(text) > 10:
        return True

    # Past tense heuristic
    if _PAST_TENSE_RE.search(text_lower):
        return True

    return False


# ---------------------------------------------------------------------------
# Importance scoring (0.0 â€“ 1.0) â€” Recalibrated 2026-02-17 [S1]
#
# Design: base=0.20, most messages 0.20-0.50, only explicit markers/decisions
# push above 0.70. Previous version had base=0.50 causing 33% at 0.9+.
# ---------------------------------------------------------------------------

_IMPORTANCE_MARKERS: List[str] = [
    "hatÄ±rla", "hatirla", "unutma", "Ã¶nemli", "onemli", "kritik",
    "acil", "kesinlikle", "mutlaka", "dikkat",
    "remember", "don't forget", "important", "critical",
    "urgent", "must", "definitely", "attention",
]

_DECISION_MARKERS: List[str] = [
    "karar", "kararlaÅŸtÄ±rdÄ±k", "kararlastirdik", "yapacaÄŸÄ±m", "yapacagim", "yapacaÄŸÄ±z", "yapacagiz",
    "sÃ¶z", "soz", "tamamdÄ±r", "tamamdir", "anlaÅŸtÄ±k", "anlastik", "kabul",
    "decided", "will do", "agreed", "commitment",
    "plan is", "going to", "promise", "deal",
]

_TASK_MARKERS: List[str] = [
    "todo", "yapÄ±lacak", "yapilacak", "gÃ¶rev", "gorev", "task",
    "action item", "next step",
]

_OPS_MARKERS: List[str] = [
    "deploy", "deployed", "restart", "restarted", "migrate", "migrated",
    "taÅŸÄ±dÄ±k", "taÅŸÄ±dÄ±m", "deploy ettim", "restart ettim",
    "config", "konfigÃ¼rasyon", ".env", "systemd", "systemctl",
    "merge", "merged", "commit", "pushed", "pull request",
    "sigkill", "oom", "crash", "hata", "error", "failed",
    "backup", "yedek", "version", "upgrade", "gÃ¼ncelle",
]

_NOISE_PATTERNS: List[str] = [
    r"^(?:ok|okay|tamam|evet|yes|no|hayÄ±r|hayir|hmm|haha|lol)$",
    r"^(?:thanks|teÅŸekkÃ¼r|tesekkur|saÄŸol|sagol)[\s!.]*$",
    r"^\d+$",
    r"^[\W]+$",
]

# System noise â€” gateway connects, test msgs, cron boilerplate
_SYSTEM_NOISE_PATTERNS = [
    re.compile(r"whatsapp gateway (?:connected|disconnected)", re.IGNORECASE),
    re.compile(r"slack (?:socket mode )?(?:connected|disconnected)", re.IGNORECASE),
    re.compile(r"^GatewayRestart:", re.IGNORECASE),
    re.compile(r"^\[queued messages", re.IGNORECASE),
    re.compile(r"^say\s+(?:ok|hello|hi|test|something)\s*$", re.IGNORECASE),
    re.compile(r"^Conversation info \(untrusted metadata\)", re.IGNORECASE),
    re.compile(r"^Replied message \(untrusted", re.IGNORECASE),
]


# Cron / automated output patterns â€” cap at 0.30
_CRON_NOISE_PATTERNS = [
    re.compile(r"^\[cron:", re.IGNORECASE),
    re.compile(r"/steward-(?:engage|post|digest)", re.IGNORECASE),
    re.compile(r"Bureau Engage", re.IGNORECASE),
    re.compile(r"steward-engage", re.IGNORECASE),
    re.compile(r"^HEARTBEAT_OK\s*$", re.IGNORECASE),
    re.compile(r"\[cron:[a-f0-9-]+\s", re.IGNORECASE),
    re.compile(r"cron job .+ just completed", re.IGNORECASE),
    re.compile(r"Return your summary as plain text", re.IGNORECASE),
    re.compile(r"Current time: \w+day,", re.IGNORECASE),
]
_CRON_NOISE_MAX = 0.30

# Conversation source indicators â€” generic by default, override via env if needed.
_DEFAULT_SLACK_DM_SOURCE_REGEX = r"Slack DM from [^:\n]+:"
_CONVERSATION_SOURCE_REGEX = os.environ.get(
    "AGENT_MEMORY_CONVERSATION_SOURCE_REGEX",
    _DEFAULT_SLACK_DM_SOURCE_REGEX,
)

try:
    _SLACK_DM_SOURCE_PATTERN = re.compile(_CONVERSATION_SOURCE_REGEX, re.IGNORECASE)
except re.error:
    _SLACK_DM_SOURCE_PATTERN = re.compile(_DEFAULT_SLACK_DM_SOURCE_REGEX, re.IGNORECASE)

_CONVERSATION_SOURCE_PATTERNS = [
    _SLACK_DM_SOURCE_PATTERN,
    # Add your own WhatsApp/phone patterns here if needed:
    # re.compile(r"\[WhatsApp \+1234567890", re.IGNORECASE),
    re.compile(r"Conversation info.*\"conversation_label\"", re.IGNORECASE | re.DOTALL),
]
_CONVERSATION_BONUS = 0.15

_TURKISH_DECISION_PATTERNS = [
    r"(?:ÅŸÃ¶yle|bÃ¶yle)\s+(?:yapalÄ±m|yapacaÄŸÄ±z|yapÄ±yoruz|gidiyoruz)",
    r"tamam\s+(?:Ã¶yle|bÃ¶yle|ÅŸÃ¶yle)\s+(?:yapalÄ±m|olsun)",
    r"(?:bence|bana gÃ¶re|benim fikrim)",
    r"(?:planÄ±mÄ±z|plan\s+ÅŸu|strateji)",
    r"(?:bu\s+kÄ±sÄ±m|bu\s+ÅŸekilde|ÅŸu\s+ÅŸekilde).*(?:olacak|olsun|yapacaÄŸÄ±z)",
    r"(?:devam\s+edelim|baÅŸlayalÄ±m|geÃ§elim)",
    r"(?:Ã¶ncelik|priority|sÄ±ra)",
]
_TURKISH_DECISION_BONUS = 0.20

# Entity stopwords â€” false positive capitals that inflate entity count
_ENTITY_STOPWORDS: set = {
    "System", "User", "Assistant", "WhatsApp", "Slack", "Session",
    "Current", "Return", "Monday", "Tuesday", "Wednesday",
    "Thursday", "Friday", "Saturday", "Sunday",
    "January", "February", "March", "April", "May", "June",
    "July", "August", "September", "October", "November", "December",
    "The", "This", "That", "Here", "There", "What", "When", "Where",
    "How", "Why", "Who", "Which", "None", "True", "False",
}


def _is_system_noise(text_lower: str) -> bool:
    """Detect gateway connects, test messages, cron boilerplate."""
    return any(p.search(text_lower) for p in _SYSTEM_NOISE_PATTERNS)


def score_importance(text: str, metadata: Optional[Dict] = None) -> float:
    """Calculate importance score for a message (0.0 â€“ 1.0).

    Recalibrated 2026-02-20: cron penalty, conversation boost, Turkish decisions.
    """
    score = 0.20
    text_lower = text.lower().strip()
    metadata = metadata or {}

    # --- early exits for noise ---
    for pattern in _NOISE_PATTERNS:
        if re.match(pattern, text_lower):
            return 0.05

    if _is_system_noise(text_lower):
        return 0.10

    # --- cron penalty: detect and cap early ---
    is_cron = any(p.search(text) for p in _CRON_NOISE_PATTERNS)
    source = metadata.get("source", "")
    if source == "cron":
        is_cron = True

    # --- conversation boost ---
    is_conversation = any(p.search(text) for p in _CONVERSATION_SOURCE_PATTERNS)
    if source in ("slack-dm", "whatsapp"):
        is_conversation = True
    if is_conversation:
        score += _CONVERSATION_BONUS

    if "?" in text and len(text) > 10:
        score += 0.05

    if any(m in text_lower for m in _IMPORTANCE_MARKERS):
        score += 0.25

    if any(m in text_lower for m in _DECISION_MARKERS):
        score += 0.20

    if any(re.search(p, text_lower) for p in _TURKISH_DECISION_PATTERNS):
        score += _TURKISH_DECISION_BONUS

    if any(m in text_lower for m in _TASK_MARKERS):
        score += 0.15

    if any(m in text_lower for m in _OPS_MARKERS):
        score += 0.20

    caps = set(re.findall(r"[A-ZÃ‡ÄžÄ°Ã–ÅžÃœ][a-zÃ§ÄŸÄ±Ã¶ÅŸÃ¼]{2,}", text))
    caps -= _ENTITY_STOPWORDS
    score += min(0.10, len(caps) * 0.02)

    word_count = len(text.split())
    if word_count > 150:
        score += 0.08
    elif word_count > 80:
        score += 0.04
    elif word_count < 8:
        score -= 0.05

    role = metadata.get("role", "")
    if role == "user":
        score += 0.05
    elif role == "qa_pair":
        score += 0.08

    if is_cron:
        score = min(score, _CRON_NOISE_MAX)

    has_decision = (
        any(m in text_lower for m in _DECISION_MARKERS)
        or any(re.search(p, text_lower) for p in _TURKISH_DECISION_PATTERNS)
    )
    if has_decision and not is_cron:
        score = max(score, 0.70)

    return max(0.05, min(1.0, score))


# ---------------------------------------------------------------------------
# Confidence tiers
# ---------------------------------------------------------------------------

def get_confidence_tier(score: float) -> str:
    """Map an importance / confidence score to a tier label.

    * ``HIGH``   â€” score > 0.85
    * ``MEDIUM`` â€” 0.60 â‰¤ score â‰¤ 0.85
    * ``LOW``    â€” score < 0.60
    """
    if score > 0.85:
        return "HIGH"
    if score >= 0.60:
        return "MEDIUM"
    return "LOW"
