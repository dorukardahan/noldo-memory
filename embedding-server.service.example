# ╔═══════════════════════════════════════════════════════════════╗
# ║  CHANGE --model path to your downloaded .gguf file          ║
# ║  CHANGE --threads to match your CPU core count              ║
# ║  Run: ./scripts/detect-hardware.sh for recommended values   ║
# ╚═══════════════════════════════════════════════════════════════╝

[Unit]
Description=Embedding Server (llama-server)
After=network.target

[Service]
Type=simple
User=root

# >>> CHANGE --model path and --threads <<<
ExecStart=/usr/local/bin/llama-server \
  --model /opt/models/Qwen3-Embedding-4B-Q8_0.gguf \
  --embedding --pooling last \
  --host 0.0.0.0 --port 8090 \
  --ctx-size 8192 --batch-size 2048 \
  --threads 12 --parallel 2

Restart=always
RestartSec=5
StandardOutput=journal
StandardError=journal
SyslogIdentifier=embedding-server

# Hardening
NoNewPrivileges=yes
ProtectSystem=strict
PrivateTmp=yes
ProtectHome=read-only
ReadWritePaths=/tmp
CapabilityBoundingSet=
UMask=0077

[Install]
WantedBy=multi-user.target
